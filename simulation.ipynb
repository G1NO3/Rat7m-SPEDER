{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import distributions as pyd\n",
    "\n",
    "from utils import util, buffer\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import NMF\n",
    "from utils import util, buffer\n",
    "import pickle\n",
    "# import h5py\n",
    "\n",
    "import os\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('model/kms/spedersac/S_f128_datasets200a200_CD_norm1_ctrl/0/args_kwargs.npy', allow_pickle=True)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter syllable 2 & 4 based on rotating direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from visualize import plot_gif\n",
    "from visualize import is_clockwise\n",
    "state_dim = 16\n",
    "action_dim = 16\n",
    "n_task = 10\n",
    "test_buffer_path = './kms/replay_buffer_mildnormalized_state200_action200.pth'\n",
    "test_buffer = buffer.ReplayBuffer(state_dim, action_dim, 10000)\n",
    "test_buffer.load_state_dict(torch.load(test_buffer_path))\n",
    "replay_buffer_filter = buffer.ReplayBuffer(state_dim, action_dim, 100000)\n",
    "for i in [2]:\n",
    "    all_idxs = np.where(test_buffer.task==i)[0]\n",
    "    transition = np.where(np.diff(all_idxs)>1)[0]\n",
    "    # print(transition)\n",
    "    transition_list = np.concatenate(([0], transition))\n",
    "    print(len(transition_list))\n",
    "    for j in range(len(transition_list)-1):\n",
    "        start = all_idxs[transition_list[j]+1]\n",
    "        end = all_idxs[transition_list[j+1]]\n",
    "        if start >= end-1:\n",
    "            continue\n",
    "        state_seqs = test_buffer.state[start:end]\n",
    "        clockwise, pc_to_plot = is_clockwise(state_seqs)\n",
    "        if (i==2 and clockwise):\n",
    "            for k in range(start, end):\n",
    "                if k == end-1:\n",
    "                    done = 1\n",
    "                else:\n",
    "                    done = 0\n",
    "                replay_buffer_filter.add(test_buffer.state[k], test_buffer.action[k], test_buffer.next_state[k], \n",
    "                                         test_buffer.reward[k], done, test_buffer.task[k], test_buffer.next_task[k])\n",
    "print(replay_buffer_filter.size)\n",
    "torch.save(replay_buffer_filter.state_dict(), './kms/replay_buffer_mildnormalized_state200_action200_filter2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize import get_edges\n",
    "def plot_figure_PC(state, save_path):\n",
    "  # state: [state_dim, ]\n",
    "  edges, state_name, n_dim = get_edges(state.shape[-1])\n",
    "  fig, axis = plt.subplots(1, 1, figsize=(5, 6))\n",
    "  state_to_plot = state.reshape(-1, 2)\n",
    "  state_to_plot -= state_to_plot.mean(axis=0)\n",
    "  _, _, vhs = np.linalg.svd(state_to_plot)\n",
    "  pc_to_plot = vhs[0]\n",
    "  cmap = plt.cm.get_cmap('viridis')\n",
    "  keypoint_colors = cmap(np.linspace(0, 1, len(state_name)))\n",
    "  xmin = -0.2\n",
    "  xmax = 0.2\n",
    "  ymin = -0.2\n",
    "  ymax = 0.2\n",
    "  # xmin = min(state_to_plot[:, 0].min(), pc_to_plot[0])\n",
    "  # xmax = max(state_to_plot[:, 0].max(), pc_to_plot[0])\n",
    "  # ymin = min(state_to_plot[:, 1].min(), pc_to_plot[1])\n",
    "  # ymax = max(state_to_plot[:, 1].max(), pc_to_plot[1])\n",
    "  axis.set_xlim(xmin, xmax)\n",
    "  axis.set_ylim(ymin, ymax)\n",
    "  for p1, p2 in edges:\n",
    "    axis.plot(\n",
    "        *state_to_plot[(p1, p2),:].T,\n",
    "        color=keypoint_colors[p1],\n",
    "        linewidth=5.0)\n",
    "  axis.scatter(\n",
    "      *state_to_plot.T,\n",
    "      c=keypoint_colors,\n",
    "      s=100)\n",
    "  axis.quiver(0, 0, pc_to_plot[0], pc_to_plot[1], angles='xy', scale_units='xy', scale=10, color='r')\n",
    "  if not os.path.exists(os.path.dirname(save_path)):\n",
    "    os.makedirs(os.path.dirname(save_path))\n",
    "  plt.savefig(save_path)\n",
    "\n",
    "state_dim = 16\n",
    "action_dim = 16\n",
    "n_task = 10\n",
    "test_buffer_path = './kms/test_data_continuous_a200.pth'\n",
    "test_buffer = buffer.ReplayBuffer(state_dim, action_dim, 10000)\n",
    "test_buffer.load_state_dict(torch.load(test_buffer_path))\n",
    "state = test_buffer.state[90]\n",
    "save_path = './figure/kms/pc.png'\n",
    "plot_figure_PC(state, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick out gif from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize import plot_gif\n",
    "state_dim = 16\n",
    "action_dim = 16\n",
    "n_task = 10\n",
    "test_buffer_path = './kms/replay_buffer_mildnormalized_state200_action200_filter2.pth'\n",
    "test_buffer = buffer.ReplayBuffer(state_dim, action_dim, 10000)\n",
    "test_buffer.load_state_dict(torch.load(test_buffer_path))\n",
    "for j in [2]:\n",
    "\n",
    "    all_idxs = np.where(test_buffer.task==j)[0]\n",
    "    print(all_idxs)\n",
    "    transition = np.where(np.diff(all_idxs)>1)[0]\n",
    "    print(transition)\n",
    "    transition_list = np.concatenate(([0], transition))\n",
    "    print(transition_list)\n",
    "    i=0\n",
    "    while i<10:\n",
    "        k = np.random.randint(0, len(all_idxs)-10)\n",
    "        start = all_idxs[k]\n",
    "        end = all_idxs[k]+10\n",
    "        done_seqs = test_buffer.done[start:end]\n",
    "        if np.sum(done_seqs) > 0:\n",
    "            continue\n",
    "        state_seqs = test_buffer.state[start:end]\n",
    "        plot_gif(state_seqs, f'./figure/kms/task_gif/task_{j}/{i}.gif')\n",
    "        i += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize import plot_gif\n",
    "state_dim = 16\n",
    "action_dim = 16\n",
    "n_task = 10\n",
    "test_buffer_path = './kms/replay_buffer_mildnormalized_state200_action200.pth'\n",
    "test_buffer = buffer.ReplayBuffer(state_dim, action_dim, 10000)\n",
    "test_buffer.load_state_dict(torch.load(test_buffer_path))\n",
    "\n",
    "for j in range(n_task):\n",
    "    all_idxs = np.where(test_buffer.task==j)[0]\n",
    "    # print(all_idxs)\n",
    "    transition = np.where(np.diff(all_idxs)>1)[0]\n",
    "    # print(transition)\n",
    "    transition_idx = all_idxs[transition]\n",
    "    all_done = test_buffer.done[transition_idx]\n",
    "    done_zero = np.where(all_done==0)[0]\n",
    "    # print(transition_idx[done_zero])\n",
    "    # original_idx = transition_idx[done_zero]\n",
    "    # print(original_idx)\n",
    "    # print(replay_buffer.state[original_idx])\n",
    "    # print()\n",
    "    # print(all_done.reshape(-1))\n",
    "    # print(np.all(np.isclose(all_done, 1)))\n",
    "    # continue\n",
    "    transition_list = np.concatenate(([0], transition))\n",
    "    print(transition_list)\n",
    "    i=0\n",
    "    while i<10:\n",
    "        \n",
    "        k = np.random.randint(0, len(transition_list)-1)\n",
    "        start = all_idxs[transition_list[k]+1]\n",
    "        end = all_idxs[transition_list[k+1]]\n",
    "        print(start, end)\n",
    "        if start == end:\n",
    "            continue\n",
    "        state_seqs = test_buffer.state[start:end]\n",
    "        plot_gif(state_seqs, f'./figure/kms/task_gif/task_{j}/{i}.gif')\n",
    "        i += 1\n",
    "        \n",
    "# state_seqs = replay_buffer.state[1172:1182]\n",
    "# plot_gif(state_seqs, f'./figure/kms/task2_continuous.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dim = 16\n",
    "action_dim = 16\n",
    "n_task = 10\n",
    "test_buffer_path = './kms/replay_buffer_mildnormalized_state200_action200.pth'\n",
    "test_buffer = buffer.ReplayBuffer(state_dim, action_dim, 10000)\n",
    "test_buffer.load_state_dict(torch.load(test_buffer_path))\n",
    "print(test_buffer.task[1150:1165].reshape(-1))\n",
    "print(test_buffer.done[1150:1165].reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_multiple_step_rollout(lr, syllable, replay_buffer):\n",
    "    syllable_idx = np.where(replay_buffer.task == syllable)[0]\n",
    "    transition = np.where(np.diff(syllable_idx) != 1)[0]+1\n",
    "    print(len(transition))\n",
    "    state_seqs = [None] * (len(transition)-1)\n",
    "    for i in range(len(transition)-1):\n",
    "        # print(transition[i], transition[i+1])\n",
    "        # print(syllable_idx[transition[i]:transition[i+1]-1])\n",
    "        state_seqs[i] = replay_buffer.state[syllable_idx[transition[i]:transition[i+1]-1]]\n",
    "        assert state_seqs[i].shape[-1] == 16\n",
    "    all_error = np.zeros(len(transition)-1)\n",
    "    for i in range(len(state_seqs)):\n",
    "        imitation_state_seq = np.zeros_like(state_seqs[i])\n",
    "        # print(state_seqs[i], transition[i], syllable_idx[transition[i]:transition[i+1]-1])\n",
    "        imitation_state_seq[0] = state_seqs[i][0]\n",
    "        for j in range(1, state_seqs[i].shape[0]):\n",
    "            imitation_state_seq[j] = lr.predict(imitation_state_seq[j-1].reshape(1, -1)).reshape(-1)\n",
    "        error = np.mean(np.abs(imitation_state_seq - state_seqs[i]))\n",
    "        # print(i, error)\n",
    "        all_error[i] = error\n",
    "    # print('all:', all_error.mean())\n",
    "    return all_error.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the fitting result of linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from visualize import plot_gif\n",
    "lr = LinearRegression()\n",
    "test_buffer_path = './kms/train_data.pth'\n",
    "replay_buffer_state_dict = torch.load(test_buffer_path)\n",
    "state_dim, action_dim = 16, 80\n",
    "test_buffer = buffer.ReplayBuffer(state_dim, action_dim, max_size=10000)\n",
    "test_buffer.load_state_dict(replay_buffer_state_dict)\n",
    "state = replay_buffer_state_dict['state']\n",
    "action = replay_buffer_state_dict['action']\n",
    "print(state.shape, action.shape)    \n",
    "action_onehot = torch.eye(action_dim)[action.long()]\n",
    "next_state = replay_buffer_state_dict['next_state']\n",
    "print(state.shape, next_state.shape)\n",
    "# sa_input = np.concatenate([state, action], axis=1)\n",
    "# split train and test buffer\n",
    "# train_buffer_size = int(0.8 * len(znormalized_state))\n",
    "# print(train_buffer_size)\n",
    "lr.fit(state, action_onehot)\n",
    "test_buffer_path = './kms/test_data.pth'\n",
    "test_buffer_state_dict = torch.load(test_buffer_path)\n",
    "test_state = test_buffer_state_dict['state']\n",
    "test_action = test_buffer_state_dict['action']\n",
    "test_action_onehot = torch.eye(action_dim)[test_action.long()]\n",
    "test_next_state = test_buffer_state_dict['next_state']\n",
    "test_action_pred = lr.predict(test_state)\n",
    "error = np.abs(test_action_pred - test_action)\n",
    "print(error.shape)\n",
    "error_mean = np.mean(error, axis=0)\n",
    "print(error_mean, error_mean.mean())\n",
    "torch.save(lr, './kms/linear_model_discrete.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from visualize import plot_gif\n",
    "from visualize import plot_gif_all_syllables\n",
    "from utils.util import unpack_batch\n",
    "train_buffer_path = './kms/train_data_continuous_a200.pth'\n",
    "train_buffer_state_dict = torch.load(train_buffer_path)\n",
    "state_dim, action_dim = 16, 16\n",
    "train_buffer = buffer.ReplayBuffer(state_dim, action_dim, max_size=10000)\n",
    "train_buffer.load_state_dict(train_buffer_state_dict)\n",
    "test_buffer_path = './kms/test_data_continuous_a200.pth'\n",
    "replay_buffer_state_dict = torch.load(test_buffer_path)\n",
    "state_dim, action_dim = 16, 16\n",
    "test_buffer = buffer.ReplayBuffer(state_dim, action_dim, max_size=10000)\n",
    "test_buffer.load_state_dict(replay_buffer_state_dict)\n",
    "timestep = 30\n",
    "state_dim = action_dim = 16\n",
    "n_syllable = 10\n",
    "state_seqs = np.zeros((n_syllable, timestep, state_dim))\n",
    "# all_error = np.zeros((10,))\n",
    "batch_size = 512\n",
    "for syllable in range(n_syllable):\n",
    "    print('syllable:', syllable)\n",
    "    lr = LinearRegression()\n",
    "    state_set = []\n",
    "    action_set = []\n",
    "    for j in range(10):\n",
    "        batch = train_buffer.sample(batch_size)\n",
    "        state, action, next_state, reward, _, task, next_task = unpack_batch(batch)\n",
    "        all_idx = np.where(task.cpu().numpy() == syllable)[0]\n",
    "        state_set.append(state[all_idx].cpu().numpy())\n",
    "        action_set.append(action[all_idx].cpu().numpy())\n",
    "    state_set = np.concatenate(state_set, axis=0)\n",
    "    action_set = np.concatenate(action_set, axis=0)\n",
    "    lr.fit(state_set, action_set)\n",
    "    # new_action_pred = lr.predict(state)\n",
    "    # error = np.abs(new_next_state_pred - next_state)\n",
    "    # print(error.shape)\n",
    "    # error_mean = np.mean(error, axis=0)\n",
    "    # print(error_mean, error_mean.mean())\n",
    "    # all_error[syllable] = check_multiple_step_rollout(lr, syllable, replay_buffer)\n",
    "    # print(syllable, all_error[syllable])\n",
    "    sample_idx = 90\n",
    "    state = test_buffer.state[sample_idx]\n",
    "    state_seqs[syllable, 0] = state\n",
    "    for i in range(1, timestep):\n",
    "        action_onehot = lr.predict(state.reshape(1, -1))\n",
    "        action = np.argmax(action_onehot.reshape(1, n_action_dim, n_action), axis=-1)\n",
    "        print('action:', action)\n",
    "        # print('action:', action.shape)\n",
    "        next_state = action + state\n",
    "        state_seqs[syllable, i] = next_state\n",
    "        state = next_state\n",
    "plot_gif_all_syllables(state_seqs, f'./figure/kms/linear_state_pred90/task.gif')\n",
    "# plot_gif(state_seqs, f'./figure/kms/linear_state_pred90/{syllable}task.gif')\n",
    "# print(state_seqs[0].shape)\n",
    "    # np.save(f'./kms/s_mean.npy', state_seqs[0].reshape(-1,2))\n",
    "# print('all:', all_error.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load replay buffer and normalize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dim = 16\n",
    "action_dim = 16\n",
    "n_task = 10\n",
    "test_buffer_path = './kms/replay_buffer_continuous_allaction.pth'\n",
    "test_buffer = buffer.ReplayBuffer(state_dim, action_dim, 10000)\n",
    "test_buffer.load_state_dict(torch.load(test_buffer_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = torch.load('./kms/linear_model_discrete.pth')\n",
    "linear_model.predict(test_buffer.state[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_factor = 200\n",
    "action_all = test_buffer.action\n",
    "print(action_all.shape[0])\n",
    "# syllable_indicator = (replay_buffer.task == 3).squeeze()\n",
    "# print(len(np.where(all_idx)[0]))\n",
    "filtered_replay_buffer = buffer.ReplayBuffer(state_dim, action_dim, 10000)\n",
    "size = test_buffer.size\n",
    "# filtered_replay_buffer.state = replay_buffer.state\n",
    "# filtered_replay_buffer.next_state = replay_buffer.next_state\n",
    "# assert np.isclose(replay_buffer.state + replay_buffer.action, replay_buffer.next_state).all()\n",
    "new_state = test_buffer.state\n",
    "new_next_state = test_buffer.next_state\n",
    "\n",
    "state_mean = np.mean(np.concatenate([new_state, new_next_state[-2:]], axis=0))\n",
    "print(state_mean)\n",
    "mildnormalized_state = (new_state - state_mean) / scale_factor\n",
    "filtered_replay_buffer.state = mildnormalized_state\n",
    "\n",
    "mildnormalized_next_state = (new_next_state - state_mean) / scale_factor\n",
    "filtered_replay_buffer.next_state = mildnormalized_next_state\n",
    "\n",
    "new_action = test_buffer.action\n",
    "filtered_replay_buffer.action = new_action/scale_factor\n",
    "# mildnormalized_action = new_action / scale_factor\n",
    "# filtered_replay_buffer.action = mildnormalized_action\n",
    "\n",
    "filtered_replay_buffer.reward = test_buffer.reward\n",
    "filtered_replay_buffer.done = test_buffer.done\n",
    "filtered_replay_buffer.task = test_buffer.task\n",
    "filtered_replay_buffer.next_task = test_buffer.next_task\n",
    "filtered_replay_buffer.size = test_buffer.size\n",
    "filtered_replay_buffer.ptr = 0\n",
    "\n",
    "# assert np.isclose(filtered_replay_buffer.state + filtered_replay_buffer.action, filtered_replay_buffer.next_state).all()\n",
    "torch.save(filtered_replay_buffer.state_dict(), './kms/replay_buffer_mildnormalized_state200_action200.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load from the whole dataset and split it into trainset and testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "state_dim = 16\n",
    "action_dim = 16\n",
    "n_task = 10\n",
    "test_buffer = buffer.ReplayBuffer(state_dim, action_dim, 10000)\n",
    "test_buffer.load_state_dict(torch.load('./kms/replay_buffer_mildnormalized200_discreteaction.pth'))\n",
    "print(np.unique(test_buffer.action))\n",
    "# action_onehot = np.eye(5)[replay_buffer.action.astype(int)]\n",
    "# assert np.isclose(test_buffer.state + test_buffer.action, test_buffer.next_state).all()\n",
    "# print(action_onehot.shape)\n",
    "# replay_buffer.action = action_onehot.reshape(action_onehot.shape[0], -1)\n",
    "# replay_buffer.action = replay_buffer.action.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349998 87500\n",
      "(array([0., 1., 2., 3., 4.]), array([  91469,  783289, 3811946,  815604,   97660]))\n",
      "(array([0., 1., 2., 3., 4.]), array([ 26997, 197144, 932390, 213929,  29540]))\n",
      "(array([0., 1.]), array([331124,  18874]))\n",
      "(array([0., 1.]), array([82830,  4670]))\n"
     ]
    }
   ],
   "source": [
    "idx = np.arange(test_buffer.size)\n",
    "# np.random.shuffle(idx)\n",
    "train_idx = idx[:int(test_buffer.size * 0.8)]\n",
    "test_idx = idx[int(test_buffer.size * 0.8):]\n",
    "train_data = {}\n",
    "test_data = {}\n",
    "key = ['state', 'action', 'next_state', 'reward', 'done', 'task', 'next_task']\n",
    "for k in key:\n",
    "    train_data[k] = test_buffer.__getattribute__(k)[train_idx]\n",
    "    test_data[k] = test_buffer.__getattribute__(k)[test_idx]\n",
    "train_data['size'] = len(train_idx)\n",
    "test_data['size'] = len(test_idx)\n",
    "train_data['ptr'] = 0\n",
    "test_data['ptr'] = 0\n",
    "# np.savez('./kms/train_data_sequential_discrete_action04.npz', **train_data)\n",
    "# np.savez('./kms/test_data_sequential_discrete_action04.npz', **test_data)\n",
    "torch.save(train_data, './kms/train_data_discrete.pth')\n",
    "torch.save(test_data, './kms/test_data_discrete.pth')\n",
    "print(len(train_idx), len(test_idx))\n",
    "print(np.unique(train_data['action'], return_counts=True))\n",
    "print(np.unique(test_data['action'], return_counts=True))\n",
    "print(np.unique(train_data['done'], return_counts=True))\n",
    "print(np.unique(test_data['done'], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3795722/(94596+784483+3795722+823329+101838)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load from raw data and creates dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc_sample = pickle.load(open('./kms/dlc_sample.pkl', 'rb'))\n",
    "print(dlc_sample.keys())\n",
    "print(dlc_sample['coordinates'].keys())\n",
    "print(dlc_sample['coordinates']['22_04_26_cage4_0.top.irDLC_resnet50_moseq_exampleAug21shuffle1_500000'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = h5py.File('./kms/results.h5', 'r')\n",
    "print(np.array(results['22_04_26_cage4_0.top.irDLC_resnet50_moseq_exampleAug21shuffle1_500000']['syllable']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllables = {k:v['syllable'] for k,v in results.items()}\n",
    "print(syllables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This proves that the states are sorted by instance frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stateseqs = {\n",
    "#         'name1': np.array([1, 1, 2, 2, 2, 3]),\n",
    "#         'name2': np.array([0, 0, 0, 1])}\n",
    "stateseq_flat = np.hstack(list(syllables.values()))\n",
    "state_onsets = np.pad(np.diff(stateseq_flat).nonzero()[0] + 1, (1, 0))\n",
    "stateseq_flat = stateseq_flat[state_onsets]\n",
    "counts = np.bincount(stateseq_flat, minlength=77)\n",
    "print(counts[:25])\n",
    "print(np.all(np.diff(counts)<=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(state, action, next_state, reward, done, task, next_task):\n",
    "    theta = np.random.uniform(0, 2*np.pi)\n",
    "    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])\n",
    "    assert state.shape == (16, )\n",
    "    assert action.shape == (16, )\n",
    "    assert next_state.shape == (16, )\n",
    "    assert np.isclose(state + action, next_state).all()\n",
    "    new_state = (state.reshape(-1,2) @ rotation_matrix).reshape(-1)\n",
    "    new_next_state = (next_state.reshape(-1,2) @ rotation_matrix).reshape(-1)\n",
    "    new_action = (action.reshape(-1,2) @ rotation_matrix).reshape(-1)\n",
    "    assert np.isclose(new_state + new_action, new_next_state).all()\n",
    "    return new_state, new_action, new_next_state, reward, done, task, next_task\n",
    "def shift(state, action, next_state, reward, done, task, next_task):\n",
    "    shift = np.random.randn(2)\n",
    "    # print('shift:', shift)\n",
    "    assert state.shape == (16, )\n",
    "    assert action.shape == (16, )\n",
    "    assert next_state.shape == (16, )\n",
    "    assert np.isclose(state + action, next_state).all()\n",
    "    new_state = (state.reshape(-1,2) + shift).reshape(-1)\n",
    "    new_next_state = (next_state.reshape(-1,2) + shift).reshape(-1)\n",
    "    new_action = action\n",
    "    # print('state:', state, new_state)\n",
    "    # print('action:', action, new_action)\n",
    "    # print('next_state:', next_state, new_next_state)\n",
    "    # print('compare:', new_state + new_action, new_next_state)\n",
    "    assert np.isclose(new_state + new_action, new_next_state).all()\n",
    "    return new_state, new_action, new_next_state, reward, done, task, next_task\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bodyparts=[\n",
    "    'tail', 'spine4', 'spine3', 'spine2', 'spine1',\n",
    "    'head', 'nose', 'right ear', 'left ear']\n",
    "use_bodyparts=[\n",
    "        'spine4', 'spine3', 'spine2', 'spine1',\n",
    "        'head', 'nose', 'right ear', 'left ear']\n",
    "use_bodyparts_idx = [bodyparts.index(bp) for bp in use_bodyparts]\n",
    "state_dim = len(use_bodyparts) * 2\n",
    "action_dim = len(use_bodyparts) * 2\n",
    "n_task = 10 # filter out some non-frsequent tasks\n",
    "extra_augmentation_step = 1\n",
    "original_replay_buffer = buffer.ReplayBuffer(state_dim, action_dim, 1000000, 'cpu')\n",
    "for name in dlc_sample['coordinates'].keys():\n",
    "    print(name)\n",
    "    for i in range(len(dlc_sample['coordinates'][name])-1):\n",
    "        state = np.array(dlc_sample['coordinates'][name][i][use_bodyparts_idx].flatten())\n",
    "        next_state = np.array(dlc_sample['coordinates'][name][i+1][use_bodyparts_idx].flatten())\n",
    "        action = next_state - state\n",
    "        task = np.array(results[name]['syllable'][i])\n",
    "        next_task = np.array(results[name]['syllable'][i+1])\n",
    "        ###这个done是否和transition_point相吻合？\n",
    "        done = np.where(next_task != task, 1, 0)\n",
    "        assert not np.all(np.isnan(state))\n",
    "        if task < n_task and next_task < n_task:\n",
    "            original_replay_buffer.add(state, action, next_state, 0, done, task, next_task)\n",
    "            # for j in range(extra_augmentation_step):\n",
    "            #     an_item = shift(*rotate(state, action, next_state, 0, 0, task, next_task))\n",
    "            #     assert np.isclose(an_item[0] + an_item[1], an_item[2]).all()\n",
    "            #     original_replay_buffer.add(*an_item)\n",
    "print(original_replay_buffer.size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(original_replay_buffer.action, return_counts=True))\n",
    "torch.save(original_replay_buffer.state_dict(), './kms/replay_buffer_continuous_allaction.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = original_replay_buffer.size\n",
    "print(original_replay_buffer.state[:10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This normalization scales every dimension with the same factor to make sure that the relative position is not discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "all_state = original_replay_buffer.state[:length]\n",
    "all_next_state = original_replay_buffer.next_state[:length]\n",
    "state_min = np.concatenate([all_state, all_next_state[-1:]]).min()\n",
    "state_max = np.concatenate([all_state, all_next_state[-1:]]).max()\n",
    "state_range = state_max - state_min\n",
    "normalized_state = (all_state - state_min) / state_range * 2 - 1\n",
    "normalized_next_state = (all_next_state - state_min) / state_range * 2 - 1\n",
    "# print(normalized_next_state.min(0), normalized_next_state.max(0))\n",
    "all_action = original_replay_buffer.action[:length]\n",
    "action_min = all_action.min()\n",
    "action_max = all_action.max()\n",
    "action_range = action_max - action_min\n",
    "normalized_action = (all_action - action_min) / action_range * 2 - 1\n",
    "# for i in range(state_dim):\n",
    "#     print(all_action[:100,i])\n",
    "#     plt.hist(all_action[:, i], bins=100)\n",
    "#     plt.show()\n",
    "for i in range(200):\n",
    "    print(all_action[i].max(), end=' ')\n",
    "####ACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_idx = np.arange(length)\n",
    "np.random.shuffle(shuffle_idx)\n",
    "train_idx = shuffle_idx[:int(length*0.8)]\n",
    "test_idx = shuffle_idx[int(length*0.8):]\n",
    "train_state = torch.FloatTensor(normalized_state[train_idx])\n",
    "train_action = torch.FloatTensor(normalized_action[train_idx])\n",
    "train_next_state = torch.FloatTensor(normalized_next_state[train_idx])\n",
    "train_task = torch.Tensor(original_replay_buffer.task[train_idx])\n",
    "train_next_task = torch.Tensor(original_replay_buffer.next_task[train_idx])\n",
    "train_reward = torch.zeros((train_state.shape[0], 1))\n",
    "train_done = torch.zeros((train_state.shape[0], 1))\n",
    "train_buffer_state_dict = {'state': train_state, \n",
    "                           'action': train_action, \n",
    "                           'next_state': train_next_state, \n",
    "                           'reward': train_reward, \n",
    "                           'done': train_done, \n",
    "                           'task': train_task, \n",
    "                           'next_task': train_next_task,\n",
    "                           'size': len(train_idx),\n",
    "                           'ptr': 0}\n",
    "test_state = torch.FloatTensor(normalized_state[test_idx])\n",
    "test_action = torch.FloatTensor(normalized_action[test_idx])\n",
    "test_next_state = torch.FloatTensor(normalized_next_state[test_idx])\n",
    "test_task = torch.Tensor(original_replay_buffer.task[test_idx])\n",
    "test_next_task = torch.Tensor(original_replay_buffer.next_task[test_idx])\n",
    "test_reward = torch.zeros((test_state.shape[0], 1))\n",
    "test_done = torch.zeros((test_state.shape[0], 1))\n",
    "test_buffer_state_dict = {'state': test_state, \n",
    "                          'action': test_action, \n",
    "                          'next_state': test_next_state, \n",
    "                          'reward': test_reward, \n",
    "                          'done': test_done, \n",
    "                          'task': test_task, \n",
    "                          'next_task': test_next_task,\n",
    "                          'size': len(test_idx),\n",
    "                          'ptr': 0}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_buffer_state_dict, './kms/train_buffer_state_dict.pth')\n",
    "torch.save(test_buffer_state_dict, './kms/test_buffer_state_dict.pth')\n",
    "print(train_state.shape, test_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_dict = {\n",
    "    'state_min': state_min,\n",
    "    'state_max': state_max,\n",
    "    'action_min': action_min,\n",
    "    'action_max': action_max\n",
    "}\n",
    "torch.save(normalize_dict, './kms/normalize_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_all = original_replay_buffer.task\n",
    "freq = np.zeros((int(task_all.max()), ))\n",
    "print(len(freq))\n",
    "for i in range(len(freq)):\n",
    "    freq[i] = len(task_all[task_all == i])\n",
    "print(np.argsort(freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dim = 54\n",
    "action_dim = 54\n",
    "n_task = 60\n",
    "original_replay_buffer = buffer.ReplayBuffer(state_dim, action_dim, 100000, 'cuda:0')\n",
    "test_buffer_path = f'./data/replay_buffer_18body_normalized_new.pth'\n",
    "original_replay_buffer.load_state_dict(torch.load(test_buffer_path))\n",
    "\n",
    "state_all, action_all, next_state_all, task_all, next_task_all, reward_all, done_all = \\\n",
    "    original_replay_buffer.state, original_replay_buffer.action, original_replay_buffer.next_state, original_replay_buffer.task,\\\n",
    "    original_replay_buffer.next_task, original_replay_buffer.reward, original_replay_buffer.done\n",
    "\n",
    "length = original_replay_buffer.size\n",
    "print(length)\n",
    "syllable_idx = np.arange(length)\n",
    "np.random.shuffle(syllable_idx)\n",
    "train_idx = torch.tensor(syllable_idx[:int(0.8*length)])\n",
    "test_idx = torch.tensor(syllable_idx[int(0.8*length):])\n",
    "print(len(train_idx), len(test_idx))\n",
    "train_buffer = buffer.ReplayBuffer(state_dim, action_dim, 100000, 'cuda:0')\n",
    "test_buffer = buffer.ReplayBuffer(state_dim, action_dim, 100000, 'cuda:0')\n",
    "for key in original_replay_buffer.state_dict().keys():\n",
    "    if key != 'ptr' and key != 'size':\n",
    "        print(key)\n",
    "        train_buffer.__setattr__(key, original_replay_buffer.__getattribute__(key)[train_idx])\n",
    "        test_buffer.__setattr__(key, original_replay_buffer.__getattribute__(key)[test_idx])\n",
    "train_buffer.size = len(train_idx)\n",
    "test_buffer.size = len(test_idx)\n",
    "print(train_buffer.size, test_buffer.size)\n",
    "train_buffer_path = './data/replay_buffer_18body_normalized_new_train.pth'\n",
    "test_buffer_path = './data/replay_buffer_18body_normalized_new_test.pth'\n",
    "torch.save(train_buffer.state_dict(), train_buffer_path)\n",
    "torch.save(test_buffer.state_dict(), test_buffer_path)\n",
    "print('Save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rat7m():\n",
    "    state_dim = 8\n",
    "    action_dim = 8\n",
    "    replay_buffer = buffer.ReplayBuffer(state_dim, action_dim, 1000000)\n",
    "    replay_buffer_path = f'../../rat7m/replay_buffer_3sigma_tanh.pth'\n",
    "    replay_buffer.load_state_dict(torch.load(replay_buffer_path))\n",
    "    print(f'Replay buffer loaded from {replay_buffer_path}')\n",
    "    return replay_buffer, state_dim, action_dim\n",
    "original_replay_buffer, state_dim, action_dim = load_rat7m()\n",
    "print(original_replay_buffer.state[:5], original_replay_buffer.action[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_notxyz = np.load('./figure/rat7m/spedersac/dim64_sa_sp_buffer_20body_normalized_lasso_1e-2/0/ig_matrix_agg.npy')\n",
    "matrix_xyz = np.load('./figure/rat7m/spedersac/dim64_sa_sp_buffer_20body_normalzied_lasso1e-2_xyz_group/0/ig_matrix_agg.npy')\n",
    "corr = np.corrcoef(matrix_notxyz.flatten(), matrix_xyz.flatten())[0, 1]\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "phi_hidden_dim = 10\n",
    "input_dim = 9  # suppose we have 2 groups, each with xyz => 2*3=6\n",
    "W = torch.randn(phi_hidden_dim, input_dim)\n",
    "\n",
    "# Original approach\n",
    "W_orig = W.reshape(phi_hidden_dim, input_dim//3, 3)\n",
    "orig_lasso = torch.sqrt(W_orig.pow(2).sum(dim=0).sum(dim=-1)).sum()\n",
    "\n",
    "# New approach\n",
    "W_t = W.T.reshape(-1, phi_hidden_dim*3)\n",
    "new_lasso = torch.norm(W_t, dim=1).sum()\n",
    "\n",
    "print(\"orig_lasso =\", orig_lasso.item())\n",
    "print(\"new_lasso  =\", new_lasso.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_name = ['HeadF','HeadB','HeadL','SpineF','SpineM',\n",
    "                'SpineL','HipL','HipR','ElbowL','ArmL',\n",
    "                'ShoulderL','ShoulderR','ElbowR','ArmR','KneeR',\n",
    "                'KneeL','ShinL','ShinR']\n",
    "# When I transfer the skeleton into edges, Please refer to the following skeleton.\n",
    "\n",
    "state_name = ['HeadF','HeadB','HeadL','SpineF','SpineM',\n",
    "              'SpineL','HipL','HipR','ElbowL','ArmL',\n",
    "              'ShoulderL','ShoulderR','ElbowR','ArmR','KneeR',\n",
    "              'KneeL','ShinL','ShinR']\n",
    "\n",
    "skeleton = [('HeadF', 'HeadB'), ('HeadF', 'HeadL'), ('HeadB', 'HeadL'),\n",
    "            ('HeadB', 'SpineF'), ('HeadL', 'SpineF'), ('SpineF', 'SpineM'),\n",
    "            ('SpineM', 'SpineL'), ('SpineF', 'ShoulderL'), ('ShoulderL', 'ElbowL'),\n",
    "            ('ElbowL', 'ArmL'), ('SpineF', 'ShoulderR'), ('ShoulderR', 'ElbowR'),\n",
    "            ('ElbowR', 'ArmR'), ('SpineM', 'HipL'), ('HipL', 'KneeL'),\n",
    "            ('KneeL', 'ShinL'), ('SpineM', 'HipR'), ('HipR', 'KneeR'),\n",
    "            ('KneeR', 'ShinR')]\n",
    "edges = []\n",
    "for i in skeleton:\n",
    "  edges.append((state_name.index(i[0]), state_name.index(i[1])))\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pca = joblib.load('./pca.p')\n",
    "print(pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_embedding(n):\n",
    "    \"\"\"\n",
    "    Generates a matrix ``Gamma`` that maps from a (n-1)-dimensional\n",
    "    vector space  to the space of k-tuples with zero mean\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Number of keypoints.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Gamma: jax array of shape (n, n - 1)\n",
    "        Matrix to map to centered embedded space.\n",
    "    \"\"\"\n",
    "    X = np.tril(np.ones((n, n)), k=-1)[1:]\n",
    "    X = np.eye(n)[1:] - X / X.sum(1)[:, None]\n",
    "    X = X / np.sqrt((X**2).sum(1))[:, None]\n",
    "    return X.T\n",
    "Gamma = np.array(center_embedding(len(state_name)))\n",
    "\n",
    "ymean = Gamma @ pca.mean_.reshape(len(state_name)-1, -1)\n",
    "ymean[state_name.index('HeadB'), 2] -= 10\n",
    "ymean[state_name.index('HeadF'), 0] += 10\n",
    "ymean[state_name.index('SpineL'), 2] += 20\n",
    "ymean[state_name.index('ShoulderL'), 0] += 20\n",
    "ymean[state_name.index('ElbowL'), 0] += 20\n",
    "ymean[state_name.index('ElbowL'), 2] += 10\n",
    "ymean[state_name.index('ArmL'), 0] += 30\n",
    "ymean[state_name.index('ArmL'), 2] += 10\n",
    "ymean[state_name.index('ArmR'), 0] += 10\n",
    "ymean[state_name.index('HipL'), 2] += 10\n",
    "ymean[state_name.index('HipL'), 0] += 30\n",
    "ymean[state_name.index('KneeL'), 2] += 10\n",
    "ymean[state_name.index('KneeL'), 0] += 30\n",
    "ymean[state_name.index('ShinL'), 2] += 10\n",
    "ymean[state_name.index('ShinL'), 0] += 30\n",
    "ymean[state_name.index('HipR'), 0] -= 10\n",
    "ymean[state_name.index('HipR'), 2] += 10\n",
    "fig, axes = plt.subplots(1, 1, figsize=(4, 4))\n",
    "dims = [0, 2]\n",
    "dims, name = [0,2], 'xz'\n",
    "cmap = plt.cm.get_cmap('viridis')\n",
    "keypoint_colors = cmap(np.linspace(0, 1, len(state_name)))\n",
    "# print(keypoint_colors)\n",
    "n_bodyparts = len(state_name)\n",
    "ig_matrix_agg_xyz = np.load('./figure/rat7m/spedersac/dim64_sa_sp_buffer_20body_normalzied_lasso1e-2_xyz_group/0/ig_matrix_agg.npy')\n",
    "for e in edges:\n",
    "    axes.plot(\n",
    "        *ymean[:, dims][e,:].T,\n",
    "        color=keypoint_colors[e[0]],\n",
    "        linewidth=5.0,\n",
    "        zorder=0)\n",
    "node_colors = ['blue' if ig_matrix_agg_xyz[0, j] < 0 else 'red' for j in range(2*n_bodyparts)]\n",
    "axes.scatter(\n",
    "        *ymean[:, dims].T,\n",
    "        c=node_colors[:n_bodyparts],\n",
    "        s=np.abs(ig_matrix_agg_xyz[0, :n_bodyparts])*120,\n",
    "        zorder=1)\n",
    "axes.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ymean.npy', ymean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mixer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
